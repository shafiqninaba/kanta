Here’s a consolidated step-by-step guide for adding Alembic to your FastAPI + SQLAlchemy Async project, configuring it for autogeneration, and managing migrations both from the CLI and programmatically.

---

## 1. Install Alembic

```bash
pip install alembic
```

If you’re using the async SQLAlchemy dialect:

```bash
pip install asyncpg
```

---

## 2. Scaffold the Migrations Directory

From your project root (where `pyproject.toml` or `requirements.txt` lives):

```bash
alembic init src/app/db/migrations
```

This creates:

```
src/app/db/migrations/
├── alembic.ini
├── env.py
├── script.py.mako
└── versions/
```

---

## 3. Configure `alembic.ini`

Open `src/app/db/migrations/alembic.ini`, find the `sqlalchemy.url` line, and set your DSN:

```ini
[alembic]
# ...

# Use the asyncpg URL so Alembic can connect
sqlalchemy.url = postgresql+asyncpg://<POSTGRES_USER>:<POSTGRES_PASSWORD>@<POSTGRES_SERVER>:<POSTGRES_PORT>/<POSTGRES_DB>
```

Replace the `<…>` placeholders accordingly.

---

## 4. Edit `env.py` for Autogeneration

By default, `env.py` has `target_metadata = None`. Change it so Alembic knows about your models:

```python
# src/app/db/migrations/env.py

import os
import sys
from logging.config import fileConfig

from sqlalchemy import engine_from_config, pool
from alembic import context

# 1) Ensure `src/` is on the path so `import app` works
sys.path.insert(
    0,
    os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "..", ".."))
)

# 2) Standard Alembic config
config = context.config
if config.config_file_name:
    fileConfig(config.config_file_name)

# 3) Import your Base and models to populate MetaData
from app.db.base import Base           # centralized declarative_base()
import app.events.models               # registers Event
import app.images.models               # registers Image & Face
# … import any other modules with models …

target_metadata = Base.metadata

# 4) The rest of `env.py` can remain as generated (offline/online functions) …
```

---

## 5. Create Your First Migration

With your models defined in code, run:

```bash
cd src/app/db/migrations
alembic revision --autogenerate -m "create initial tables"
```

Alembic will compare `Base.metadata` against your DB and emit a new file under `versions/` containing `op.create_table(...)` calls.

---

## 6. Apply Migrations

```bash
alembic upgrade head
```

This executes all pending migrations in order, bringing your schema up to date.

---

## 7. Evolving Your Schema

Whenever you add or change columns/models:

1. **Generate** a new migration:

   ```bash
   alembic revision --autogenerate -m "add description column to events"
   ```
2. **Review** the generated script in `versions/` to ensure it matches your intent.
3. **Apply** it:

   ```bash
   alembic upgrade head
   ```

---

## 8. Programmatic Migrations (Optional)

You can also invoke Alembic from Python—handy in scripts or CI:

```python
# scripts/migrate.py

import sys
from alembic.config import Config
from alembic import command

ALEMBIC_INI = "src/app/db/migrations/alembic.ini"

def make_revision(message: str):
    cfg = Config(ALEMBIC_INI)
    command.revision(cfg, message=message, autogenerate=True)

def upgrade_head():
    cfg = Config(ALEMBIC_INI)
    command.upgrade(cfg, "head")

if __name__ == "__main__":
    action = sys.argv[1]
    if action == "revision":
        make_revision(sys.argv[2])
    elif action == "upgrade":
        upgrade_head()
    else:
        print("Usage: migrate.py [revision <msg> | upgrade]")
```

Then:

```bash
python scripts/migrate.py revision "add description to events"
python scripts/migrate.py upgrade
```

---

## 9. Integrate in App Startup (Optional)

If you prefer to auto-apply migrations whenever your service boots (common in dev):

```python
# in src/app/main.py, inside your lifespan/startup:
from alembic.config import Config
from alembic import command

def run_migrations():
    cfg = Config("src/app/db/migrations/alembic.ini")
    command.upgrade(cfg, "head")

@asynccontextmanager
async def lifespan(app: FastAPI):
    # apply migrations
    run_migrations()
    # then your existing startup logic…
```

> ⚠️ **Warning**: In production it’s usually safer to run migrations as a separate deployment step rather than auto-applying them in-process.

---

## 10. Best Practices

* **Commit each migration file** into version control.
* **Review autogenerated code** for correctness (e.g., default values, nullable flags).
* **Tag or branch** your repo before big schema changes.
* **Seed your database** with a “head” migration in CI to ensure migrations remain idempotent.

---

With this in place, you’ve got a robust, versioned migration workflow that keeps your database schema synchronized with your SQLAlchemy models—no more “missing column” errors in production.
